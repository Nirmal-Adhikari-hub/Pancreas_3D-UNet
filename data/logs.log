Using 3 GPUs on cudaUsing 3 GPUs on cuda

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

Number of patches: 2, 
 Number of Labels: 2Number of patches: 2, 
 Number of Labels: 2

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 8, 
 Number of Labels: 8Number of patches: 8, 
 Number of Labels: 8

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([16, 32, 512, 512]), Labels -> torch.Size([16, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([16, 32, 512, 512]), Labels -> torch.Size([16, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 2, 
 Number of Labels: 2Number of patches: 2, 
 Number of Labels: 2

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 194, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 194, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 194, in <module>
            for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:


                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
            data = self._next_data()data = self._next_data()data = self._next_data()


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
            return self._process_data(data)return self._process_data(data)return self._process_data(data)


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
            data.reraise()data.reraise()data.reraise()


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
            raise exceptionraise exceptionraise exception


RuntimeErrorRuntimeErrorRuntimeError: : : Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizableUsing 3 GPUs on cudaUsing 3 GPUs on cuda

Using 3 GPUs on cudaUsing 3 GPUs on cuda

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

Using 3 GPUs on cudaUsing 3 GPUs on cuda

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 3, 
 Number of Labels: 3Number of patches: 3, 
 Number of Labels: 3

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 7, 
 Number of Labels: 7Number of patches: 7, 
 Number of Labels: 7

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 2, 
 Number of Labels: 2Number of patches: 2, 
 Number of Labels: 2

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([14, 32, 512, 512]), Labels -> torch.Size([14, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([14, 32, 512, 512]), Labels -> torch.Size([14, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])

Number of patches: 23, 
 Number of Labels: 23Number of patches: 23, 
 Number of Labels: 23

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 8, 
 Number of Labels: 8Number of patches: 8, 
 Number of Labels: 8

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([16, 32, 512, 512]), Labels -> torch.Size([16, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([16, 32, 512, 512]), Labels -> torch.Size([16, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 7, 
 Number of Labels: 7Number of patches: 7, 
 Number of Labels: 7

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 200, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 200, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 200, in <module>
            for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:


                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
            data = self._next_data()data = self._next_data()data = self._next_data()


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
            return self._process_data(data)return self._process_data(data)return self._process_data(data)


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
            data.reraise()data.reraise()data.reraise()


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
            raise exceptionraise exceptionraise exception


RuntimeErrorRuntimeErrorRuntimeError: : : Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable



Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([46, 32, 512, 512]), Labels -> torch.Size([46, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([46, 32, 512, 512]), Labels -> torch.Size([46, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 11, 
 Number of Labels: 11Number of patches: 11, 
 Number of Labels: 11

Number of patches: 3, 
 Number of Labels: 3Number of patches: 3, 
 Number of Labels: 3

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 200, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 200, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 200, in <module>
            for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:


                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
            data = self._next_data()data = self._next_data()data = self._next_data()


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
            return self._process_data(data)return self._process_data(data)return self._process_data(data)


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
            data.reraise()data.reraise()data.reraise()


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
            raise exceptionraise exceptionraise exception


RuntimeErrorRuntimeErrorRuntimeError: : : Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [10, 32, 512, 512] at entry 0 and [6, 32, 512, 512] at entry 1
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [10, 32, 512, 512] at entry 0 and [6, 32, 512, 512] at entry 1
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [10, 32, 512, 512] at entry 0 and [6, 32, 512, 512] at entry 1



Number of patches: 3, 
 Number of Labels: 3Number of patches: 3, 
 Number of Labels: 3

After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([22, 32, 512, 512]), Labels -> torch.Size([22, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([22, 32, 512, 512]), Labels -> torch.Size([22, 32, 512, 512])

Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 183, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 183, in <module>
        from models.unet3d import UNet3Dfrom models.unet3d import UNet3D

  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/models/unet3d.py", line 2, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/models/unet3d.py", line 2, in <module>
        from torchsummary import summaryfrom torchsummary import summary

ModuleNotFoundErrorModuleNotFoundError: : No module named 'torchsummary'No module named 'torchsummary'

Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 183, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 183, in <module>
        from models.unet3d import UNet3Dfrom models.unet3d import UNet3D

  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/models/unet3d.py", line 2, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/models/unet3d.py", line 2, in <module>
        from torchsummary import summaryfrom torchsummary import summary

ModuleNotFoundErrorModuleNotFoundError: : No module named 'torchsummary'No module named 'torchsummary'

Using 3 GPUs on cudaUsing 3 GPUs on cuda

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 7, 
 Number of Labels: 7Number of patches: 7, 
 Number of Labels: 7

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([14, 32, 512, 512]), Labels -> torch.Size([14, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([14, 32, 512, 512]), Labels -> torch.Size([14, 32, 512, 512])

Number of patches: 2, 
 Number of Labels: 2Number of patches: 2, 
 Number of Labels: 2

After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

Number of patches: 10, 
 Number of Labels: 10Number of patches: 10, 
 Number of Labels: 10

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 3, 
 Number of Labels: 3Number of patches: 3, 
 Number of Labels: 3

After Augmentation: 
 Patches - torch.Size([20, 32, 512, 512]), Labels -> torch.Size([20, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([20, 32, 512, 512]), Labels -> torch.Size([20, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
            for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:


                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
            data = self._next_data()data = self._next_data()data = self._next_data()


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
            return self._process_data(data)return self._process_data(data)return self._process_data(data)


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
            data.reraise()data.reraise()data.reraise()


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
            raise exceptionraise exceptionraise exception


RuntimeErrorRuntimeErrorRuntimeError: : : Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [10, 32, 512, 512] at entry 0 and [4, 32, 512, 512] at entry 1
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [10, 32, 512, 512] at entry 0 and [4, 32, 512, 512] at entry 1
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [10, 32, 512, 512] at entry 0 and [4, 32, 512, 512] at entry 1



Using 3 GPUs on cudaUsing 3 GPUs on cuda

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

Using 3 GPUs on cudaUsing 3 GPUs on cuda

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

Using 3 GPUs on cudaUsing 3 GPUs on cuda

World Size: 1 
 Local Rank: 0World Size: 1 
 Local Rank: 0

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 2, 
 Number of Labels: 2Number of patches: 2, 
 Number of Labels: 2

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

Number of patches: 3, 
 Number of Labels: 3Number of patches: 3, 
 Number of Labels: 3

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 8, 
 Number of Labels: 8Number of patches: 8, 
 Number of Labels: 8

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([6, 32, 512, 512]), Labels -> torch.Size([6, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 10, 
 Number of Labels: 10Number of patches: 10, 
 Number of Labels: 10

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([16, 32, 512, 512]), Labels -> torch.Size([16, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([16, 32, 512, 512]), Labels -> torch.Size([16, 32, 512, 512])

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
            for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:


                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
            data = self._next_data()data = self._next_data()data = self._next_data()


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
            return self._process_data(data)return self._process_data(data)return self._process_data(data)


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
            data.reraise()data.reraise()data.reraise()


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
            raise exceptionraise exceptionraise exception


RuntimeErrorRuntimeErrorRuntimeError: : : Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [8, 32, 512, 512] at entry 0 and [10, 32, 512, 512] at entry 1
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [8, 32, 512, 512] at entry 0 and [10, 32, 512, 512] at entry 1
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: stack expects each tensor to be equal size, but got [8, 32, 512, 512] at entry 0 and [10, 32, 512, 512] at entry 1



Number of patches: 23, 
 Number of Labels: 23Number of patches: 23, 
 Number of Labels: 23

/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  aug_patch_tensor = torch.tensor(aug_patch)
Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

Number of patches: 2, 
 Number of Labels: 2Number of patches: 2, 
 Number of Labels: 2

After Augmentation: 
 Patches - torch.Size([20, 32, 512, 512]), Labels -> torch.Size([20, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([20, 32, 512, 512]), Labels -> torch.Size([20, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 7, 
 Number of Labels: 7Number of patches: 7, 
 Number of Labels: 7

Number of patches: 4, 
 Number of Labels: 4Number of patches: 4, 
 Number of Labels: 4

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([14, 32, 512, 512]), Labels -> torch.Size([14, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([14, 32, 512, 512]), Labels -> torch.Size([14, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([8, 32, 512, 512]), Labels -> torch.Size([8, 32, 512, 512])

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

Number of patches: 5, 
 Number of Labels: 5Number of patches: 5, 
 Number of Labels: 5

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 2, 
 Number of Labels: 2Number of patches: 2, 
 Number of Labels: 2

After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([10, 32, 512, 512]), Labels -> torch.Size([10, 32, 512, 512])

Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([4, 32, 512, 512]), Labels -> torch.Size([4, 32, 512, 512])

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 204, in <module>
            for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:for batch_data, batch_labels in train_loader:


                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
            data = self._next_data()data = self._next_data()data = self._next_data()


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
            return self._process_data(data)return self._process_data(data)return self._process_data(data)


                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
            data.reraise()data.reraise()data.reraise()


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
            raise exceptionraise exceptionraise exception


RuntimeErrorRuntimeErrorRuntimeError: : : Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable
Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py", line 213, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable



Number of patches: 6, 
 Number of Labels: 6Number of patches: 6, 
 Number of Labels: 6

After Augmentation: 
 Patches - torch.Size([46, 32, 512, 512]), Labels -> torch.Size([46, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([46, 32, 512, 512]), Labels -> torch.Size([46, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])After Augmentation: 
 Patches - torch.Size([12, 32, 512, 512]), Labels -> torch.Size([12, 32, 512, 512])

Using 3 GPUs on cudaUsing 3 GPUs on cuda

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
            train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)


                                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
            if torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logs


                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
            default_pg = _get_default_group()default_pg = _get_default_group()default_pg = _get_default_group()


                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
            raise ValueError(raise ValueError(raise ValueError(


ValueErrorValueErrorValueError: : : Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.


Using 3 GPUs on cudaUsing 3 GPUs on cuda

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
            train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)


                                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
            if torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logs


                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
            default_pg = _get_default_group()default_pg = _get_default_group()default_pg = _get_default_group()


                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
            raise ValueError(raise ValueError(raise ValueError(


ValueErrorValueErrorValueError: : : Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.


Using 3 GPUs on cudaUsing 3 GPUs on cuda

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
            train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)


                                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
            if torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logs


                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
            default_pg = _get_default_group()default_pg = _get_default_group()default_pg = _get_default_group()


                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
            raise ValueError(raise ValueError(raise ValueError(


ValueErrorValueErrorValueError: : : Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.


Using 1 GPUs on cudaUsing 1 GPUs on cuda

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 196, in <module>
  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 196, in <module>
  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 196, in <module>
            train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)


                                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 152, in get_dataloaders
  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 152, in get_dataloaders
  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 152, in get_dataloaders
            train_dataset = PancreasDataset(config, train=True)train_dataset = PancreasDataset(config, train=True)train_dataset = PancreasDataset(config, train=True)


                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 51, in __init__
  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 51, in __init__
  File "d:\Nirmal\pancreas\3D-UNet\data\dataloader.py", line 51, in __init__
            with open(config.dataset_json, 'r') as f:with open(config.dataset_json, 'r') as f:with open(config.dataset_json, 'r') as f:


                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


FileNotFoundErrorFileNotFoundErrorFileNotFoundError: : : [Errno 2] No such file or directory: '/shared/home/xvoice/nirmal/data/Task07_Pancreas/dataset.json'[Errno 2] No such file or directory: '/shared/home/xvoice/nirmal/data/Task07_Pancreas/dataset.json'[Errno 2] No such file or directory: '/shared/home/xvoice/nirmal/data/Task07_Pancreas/dataset.json'


Using 3 GPUs on cudaUsing 3 GPUs on cuda

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
            train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)


                                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
            if torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logs


                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
            default_pg = _get_default_group()default_pg = _get_default_group()default_pg = _get_default_group()


                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
            raise ValueError(raise ValueError(raise ValueError(


ValueErrorValueErrorValueError: : : Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.


Using 3 GPUs on cudaUsing 3 GPUs on cuda

Using 3 GPUs on cudaUsing 3 GPUs on cuda

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
            train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)


                                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
            if torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logs


                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
            default_pg = _get_default_group()default_pg = _get_default_group()default_pg = _get_default_group()


                                                   Traceback (most recent call last):
^Traceback (most recent call last):
^^Traceback (most recent call last):
^^^^^  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
^  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
^  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 196, in <module>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    
        train_loader, val_loader = get_dataloaders(config)train_loader, val_loader = get_dataloaders(config)  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
train_loader, val_loader = get_dataloaders(config)  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group



                                                                                       raise ValueError( raise ValueError( raise ValueError( 
 
 
    ValueError ValueError ValueError :  :  :  Default process group has not been initialized, please make sure to call init_process_group. Default process group has not been initialized, please make sure to call init_process_group. Default process group has not been initialized, please make sure to call init_process_group. 
^
^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
  File "/shared/home/xvoice/nirmal/project/Unet_seg/Pancreas_3D-UNet/data/dataloader.py", line 158, in get_dataloaders
            if torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logsif torch.distributed.get_rank() == 0:  # Ensure only the main process logs


                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1809, in get_rank
            default_pg = _get_default_group()default_pg = _get_default_group()default_pg = _get_default_group()


                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
  File "/shared/home/xvoice/anaconda3/envs/transformer_mm/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py", line 1025, in _get_default_group
            raise ValueError(raise ValueError(raise ValueError(


ValueErrorValueErrorValueError: : : Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.Default process group has not been initialized, please make sure to call init_process_group.


